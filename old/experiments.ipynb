{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 02-23 17:04:45 __init__.py:190] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.621 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "      (1): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "      (2-31): 30 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from unsloth import FastLanguageModel\n",
    "from typing import Optional\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "                model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B-unsloth-bnb-4bit\",\n",
    "                max_seq_length=4096,\n",
    "            )\n",
    "\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>Welcome to the 5-Round Decision Simulation!\n",
      "\n",
      "Your Task:\n",
      "You will participate in a game that unfolds over 5 rounds. In each round, you will see one or more active cues positioned in different quadrants. Among these cues, one quadrant is biased—the cue there appears with a 90% probability of one color and a 10% chance of another, while cues in the other quadrants follow a 50/50 color distribution. Keep in mind that at least one cue is active in every round, and each cue will disappear after a random duration.\n",
      "\n",
      "Your Goal:\n",
      "After completing all 5 rounds, you must identify which quadrant was biased.\n",
      "- A correct answer awards +100 points.\n",
      "- An incorrect answer deducts -100 points.\n",
      "\n",
      "Round 1 Instructions:\n",
      "The available cue is in Quadrant B. Based on the information provided so far, select one cue by simply responding with the corresponding letter.\n",
      "\n",
      "Press your chosen letter to continue.<｜Assistant｜><think>\n",
      "Okay, so I'm trying to figure out which quadrant was biased across 5 rounds of this game. Let me start by understanding the problem step by step.\n",
      "\n",
      "First, each round has active cues in different quadrants. One quadrant is biased, meaning the cue there has a 90% chance of one color and 10% of another. The other quadrants have a 50/50 chance. Also, each cue disappears after a random duration, so they don't stick around forever.\n",
      "\n",
      "My goal is to determine which quadrant was biased after completing all 5 rounds. Each time I make a correct answer, I get +100 points, and if I'm wrong, I lose 100 points. So, I need to be accurate in each round to maximize my points.\n",
      "\n",
      "Let me break down each round as per the instructions given.\n",
      "\n",
      "Round 1:\n",
      "The available cue is in Quadrant B. The user says to respond with the corresponding letter, which is B. So, I just press B here. That was straightforward.\n",
      "\n",
      "Round 2:\n",
      "Wait, but after Round 1, the cue in B disappears after a random duration. So, in Round 2, the cue might not be there anymore. But the user hasn't provided specific information for Round 2 yet. Let me think about how to approach Round 2.\n",
      "\n",
      "In Round 2, the user says that in each round, there are active cues in different quadrants, and one is biased. So, after Round 1, the cue in B is gone, so in Round 2, there must be cues in other quadrants, with one being biased. But I don't know which one yet.\n",
      "\n",
      "Wait, but the problem says that in each round, you see one or more active cues in different quadrants. So, in Round 2, the cues could be in any quadrants except B, or maybe including B if the duration was long enough. But the duration is random, so I don't know.\n",
      "\n",
      "Wait, the problem says each cue disappears after a random duration. So, the cue in B could come back in Round 2 if its duration was longer than the time between rounds. But I don't know the exact timing. So, perhaps in Round 2, I might see cues in other quadrants, and I have to figure out which one is biased.\n",
      "\n",
      "But the user hasn't provided specific information about Round 2 yet. Wait, the initial instruction for Round 1 was to respond with B, but the user hasn't provided the same for Round 2. So, perhaps in Round 2, the available cue is in a different quadrant, and I need to figure it out based on the previous information.\n",
      "\n",
      "Wait, maybe I'm overcomplicating. Let me try to approach this methodically.\n",
      "\n",
      "After completing all 5 rounds, I need to identify the biased quadrant. Each round gives me information about the cues in that round, and I can use that to update my knowledge about which quadrant is biased.\n",
      "\n",
      "Let me consider that in each round, the biased quadrant is the same or different. The problem doesn't specify that the biased quadrant changes each round, so it could stay the same or change. Therefore, I need to track over 5 rounds.\n",
      "\n",
      "But the problem is that each cue disappears after a random duration, so I don't know how long each cue was active. Therefore, the information from each round is that in that round, the active cues were in certain quadrants, and one was biased.\n",
      "\n",
      "Wait, but the user hasn't provided the specific cues for each round beyond Round 1. So, perhaps the user is asking me to process the information as it comes in each round and figure out which quadrant is biased at the end.\n",
      "\n",
      "Wait, perhaps the user is providing the information in each round, and I need to respond with the letter corresponding to the biased quadrant in each round, and at the end, the user will tell me whether my answer was correct or not.\n",
      "\n",
      "But in the initial prompt, the user only provided information for Round 1, instructing to respond with B. So, perhaps the rest of the rounds will follow similarly, and I need to respond with the corresponding letters for each round, and then at the end, the user will tell me whether I was correct or not.\n",
      "\n",
      "Wait, but the user's instruction ends with \"Press your chosen letter to continue.\" So, perhaps in each round, the user will present the information, and I need to respond with the letter corresponding to the biased quadrant in that round.\n",
      "\n",
      "Wait, but without knowing the specific information for each round beyond Round 1, I can't proceed. So, perhaps the user is testing me on how I would approach each round to determine the biased quadrant, using the information from each round.\n",
      "\n",
      "Alternatively, maybe the user is providing a scenario where after each round, I have to make a decision based on the information available up to that point, and then at the end, based on all 5 rounds, determine the quadrant.\n",
      "\n",
      "Wait, perhaps I'm overcomplicating. Let me try to outline the approach I would take if I were playing this game.\n",
      "\n",
      "First, I need to track which quadrants were biased in which rounds. Since each round can have a different biased quadrant, I need to consider that possibility.\n",
      "\n",
      "In Round 1, the cue was in Quadrant B, and it was biased. So, I can note that B is a possible candidate.\n",
      "\n",
      "In Round 2, suppose the cue was in Quadrant A. If I saw it and it was biased, then I would note that A is a candidate. But if it wasn't biased, then A isn't the biased quadrant.\n",
      "\n",
      "Similarly, in Round 3, if the cue was in Quadrant C and it was biased, then C is a candidate.\n",
      "\n",
      "In Round 4, if the cue was in Quadrant D and it was biased, then D is a candidate.\n",
      "\n",
      "In Round 5, again, depending on where the cue is, I can note the quadrant.\n",
      "\n",
      "But the problem is that each cue disappears after a random duration, so I don't know how many times each quadrant has been active. Therefore, I can't be sure how many times I saw a cue from a particular quadrant.\n",
      "\n",
      "Wait, but in each round, there is at least one cue active, and I see it. So, for each round, I know which quadrants had active cues, and among them, one was biased.\n",
      "\n",
      "Therefore, over 5 rounds, I can track the quadrants that had a biased cue in that round.\n",
      "\n",
      "But the user hasn't provided the specific information for each round beyond Round 1, so perhaps I need to consider that the user is asking me to process the information as it comes in each round and then determine the quadrant at the end.\n",
      "\n",
      "Wait, perhaps the user is asking me to simulate the process of playing the game, where in each round, I respond with the letter corresponding to the biased quadrant, and then at the end, I get a score based on how many times I was correct.\n",
      "\n",
      "But without specific information for each round beyond Round 1, I can't proceed further. So, perhaps the user is testing me on how I would approach each round to determine the biased quadrant, using the information from each round.\n",
      "\n",
      "Alternatively, perhaps the user is providing a scenario where after each round, I have to make a decision based on the information available up to that point, and then at the end, based on all 5 rounds, determine the quadrant.\n",
      "\n",
      "Wait, I think I'm going in circles here. Let me try to approach this differently.\n",
      "\n",
      "Each round, I see a cue in one or more quadrants, and one of them is biased. I need to determine which quadrant is biased after all 5 rounds.\n",
      "\n",
      "But since each cue disappears after a random duration, I don't know how many times each quadrant was active. However, in each round, I see the active cues, and I can note which quadrant was biased in that round.\n",
      "\n",
      "So, over 5 rounds, I can track the quadrants where a biased cue was active. The quadrant that appears in all 5 rounds is likely the correct answer, but it could be any quadrant.\n",
      "\n",
      "Wait, but without knowing which quadrants were active in each round, I can't track this. So, perhaps the user is asking me to consider that in each round, the biased quadrant is the same or different.\n",
      "\n",
      "Alternatively, perhaps the user is asking me to consider that the biased quadrant is the same across all rounds, and I have to determine which quadrant it is based on the information from each round.\n",
      "\n",
      "But again, without specific information, I can't determine that.\n",
      "\n",
      "Wait, perhaps the user is providing a scenario where after each round, I have to make a decision, and then at the end, based on all 5 rounds, I have to identify the quadrant.\n",
      "\n",
      "But since I don't have the specific information for each round beyond Round 1, I can't proceed.\n",
      "\n",
      "Wait, perhaps the user is testing me on how I would approach each round, and I need to respond with the corresponding letter for each round, and then at the end, the user will tell me whether I was correct or not.\n",
      "\n",
      "In that case, for Round 1, I responded with B, as instructed.\n",
      "\n",
      "Now, for Round 2, I need to consider what information I have. Since the cue in B is gone after a random duration, in Round 2, the cue might be in another quadrant. But I don't know which one. So, I have to make a guess based on the information available.\n",
      "\n",
      "Wait, but the problem says that in each round, at least one cue is active, and each cue disappears</think>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Welcome to the 5-Round Decision Simulation!\\n\\nYour Task:\\nYou will participate in a game that unfolds over 5 rounds. In each round, you will see one or more active cues positioned in different quadrants. Among these cues, one quadrant is biased—the cue there appears with a 90% probability of one color and a 10% chance of another, while cues in the other quadrants follow a 50/50 color distribution. Keep in mind that at least one cue is active in every round, and each cue will disappear after a random duration.\\n\\nYour Goal:\\nAfter completing all 5 rounds, you must identify which quadrant was biased.\\n- A correct answer awards +100 points.\\n- An incorrect answer deducts -100 points.\\n\\nRound 1 Instructions:\\nThe available cue is in Quadrant B. Based on the information provided so far, select one cue by simply responding with the corresponding letter.\\n\\nPress your chosen letter to continue.\"\n",
    "tokenized_prompt = tokenizer.encode(f\"<｜begin▁of▁sentence｜><｜User｜>{prompt}<｜Assistant｜>\", return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n",
    "\n",
    "min_thinking_time = 20   # minimum thinking time in seconds\n",
    "max_thinking_time = 40   # maximum thinking time in seconds\n",
    "batch_tokens = 20        # Generate tokens in small batches\n",
    "replacement_text = \"Wait\"  # Replacement text if end is premature\n",
    "\n",
    "# Encode markers.\n",
    "start_think_token = tokenizer.encode(\"<think>\", add_special_tokens=False)[0]\n",
    "end_think_token = tokenizer.encode(\"</think>\", add_special_tokens=False)[0]\n",
    "replacement_ids = tokenizer.encode(replacement_text, add_special_tokens=False)\n",
    "\n",
    "is_thinking = True       # Are we in the thinking phase?\n",
    "finished = False\n",
    "final_tokens = tokenized_prompt\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "while not finished:\n",
    "    outputs = model.generate(input_ids=final_tokens,max_new_tokens=batch_tokens,do_sample=True,temperature=0.6,top_p=0.95)\n",
    "    new_tokens = outputs[:, final_tokens.shape[1]:]  # Only newly generated tokens\n",
    "    for token in new_tokens[0]:  # Iterate over tokens\n",
    "        elapsed_time = time.time() - start_time # Check if the maximum thinking time has been reached\n",
    "        if elapsed_time >= max_thinking_time: # Append end-of-think token and break out of the loop\n",
    "            final_tokens = torch.cat([final_tokens, torch.tensor([[end_think_token]]).to(final_tokens.device)], dim=1)\n",
    "            finished = True\n",
    "            break\n",
    "        token_id = token.item()\n",
    "        if token_id == end_think_token and is_thinking:  # Detect </think> token\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time < min_thinking_time:  # If we haven't \"thought\" long enough\n",
    "                final_tokens = torch.cat([final_tokens, torch.tensor([replacement_ids]).to(final_tokens.device)], dim=1) # Replace premature </think> with replacement text.\n",
    "                continue\n",
    "            else:  # If we have \"thought\" long enough\n",
    "                is_thinking = False\n",
    "                finished = True\n",
    "        final_tokens = torch.cat([final_tokens, token.unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "        if token_id == end_think_token:\n",
    "            finished = True\n",
    "            break\n",
    "    if finished:\n",
    "        break\n",
    "\n",
    "output_text = tokenizer.decode(final_tokens[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "# Use the output_text as the new prompt to generate a single answer token.\n",
    "conclusive_text = \"\\nThe answer is <<\"\n",
    "input_ids = tokenizer.encode(output_text+conclusive_text, return_tensors=\"pt\").to(final_tokens.device)\n",
    "answer_output = model.generate(input_ids=input_ids, max_new_tokens=2, do_sample=True, temperature=0.6, top_p=0.95)\n",
    "answer_text = tokenizer.decode(answer_output[0, -2], skip_special_tokens=True)\n",
    "print(answer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
